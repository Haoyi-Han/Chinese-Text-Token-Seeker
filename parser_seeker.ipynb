{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 从中文文本中抽取所有含指定关键字的语句"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "首先加载指定的扩展包：python-docx，re，json。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import re\r\n",
    "import json\r\n",
    "try:\r\n",
    "    from docx import Document\r\n",
    "except:\r\n",
    "    !pip install python-docx\r\n",
    "    from docx import Document"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "利用python-docx将docx文档读取后分段，生成段落字典。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def page_divider(doc_file):\r\n",
    "    document = Document(doc_file)\r\n",
    "    doc_dict = {}\r\n",
    "    count = 1\r\n",
    "    for par in document.paragraphs:\r\n",
    "        if par.text != '':\r\n",
    "            p1 = re.compile('^\\s+|\\s+$|\\n')\r\n",
    "            doc_dict[str(count)] = re.sub(p1, '', par.text)\r\n",
    "            count += 1\r\n",
    "    return doc_dict, count-1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "利用正则表达式将各段落依照标点符号分句，并在句尾适当补充句号和引号。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def partext_tokenizer(partext):\r\n",
    "    phrlist = re.split('[。？！][’”』」]|。|？|！', partext)\r\n",
    "    phrase_list = []\r\n",
    "    for s in phrlist:\r\n",
    "        s += '。'\r\n",
    "        if s.count('‘') > s.count('’'):\r\n",
    "            s += '’'\r\n",
    "        if s.count('“') > s.count('”'):\r\n",
    "            s += '”'\r\n",
    "        if s.count('『') > s.count('』'):\r\n",
    "            s += '』'\r\n",
    "        if s.count('「') > s.count('」'):\r\n",
    "            s += '」'\r\n",
    "        phrase_list.append(s)\r\n",
    "    return phrase_list"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "将所有段落分句后逐个按关键字查找，将符合条件的整理成一个字典输出为json文件。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def text_seeker(doc_path, keyword, outpath, outjson=True, outtxt=True):\r\n",
    "    doc_dict, pagenum = page_divider(doc_path)\r\n",
    "    out_dict = {}\r\n",
    "    for i in range(1, pagenum+1):\r\n",
    "        num = str(i)\r\n",
    "        ss = partext_tokenizer(doc_dict[num])\r\n",
    "        out_dict[num] = [s for s in ss if keyword in s]\r\n",
    "        if out_dict[num] == []:\r\n",
    "            del out_dict[num]\r\n",
    "    if outjson:\r\n",
    "        with open(outpath+'.json', 'w', encoding='utf-8') as g:\r\n",
    "            json.dump(out_dict, fp=g, indent=4)\r\n",
    "    if outtxt:\r\n",
    "        with open(outpath+'.txt', 'w', encoding='utf-8') as j:\r\n",
    "            out_list = [s for ss in out_dict.values() for s in ss]\r\n",
    "            j.write('\\n'.join(out_list))\r\n",
    "    print(len(out_dict))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "设定输入文件路径，待查找关键字，输出文件路径"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "text_seeker('1. 春秋左传原文.docx', '在', 'output', outjson=True, outtxt=True)\r\n",
    "text_seeker('01. 春秋左传 简体原文+译文 (1).docx', '在', 'output2', outjson=True, outtxt=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "345\n",
      "1745\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit"
  },
  "interpreter": {
   "hash": "c2bb4c3659b3800c6f5c337833d4b61a13da9254187e1e335ac6d827c94feba0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}